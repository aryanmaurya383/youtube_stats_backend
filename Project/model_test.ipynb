{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ada1b682",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Abhishek Pandey\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.2.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Final Deployment Script\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import pickle\n",
    "import os\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# -------------------------------\n",
    "# Load all required artifacts\n",
    "# -------------------------------\n",
    "\n",
    "# Load GloVe model\n",
    "glove_model = KeyedVectors.load_word2vec_format('Model_dir\\glove.6B.50d.word2vec.txt', binary=False)\n",
    "\n",
    "# Load LabelEncoders\n",
    "with open('Model_dir\\le_country.pkl', 'rb') as f:\n",
    "    le_country = pickle.load(f)\n",
    "\n",
    "with open('Model_dir\\le_category.pkl', 'rb') as f:\n",
    "    le_category = pickle.load(f)\n",
    "\n",
    "# Load trained LightGBM models\n",
    "models = {}\n",
    "target_cols = ['#views', '#comments', '#likes', '#dislikes']\n",
    "for target in target_cols:\n",
    "    model_path = f'Model_dir/models/lgb_{target}.txt'\n",
    "    models[target] = lgb.Booster(model_file=model_path)\n",
    "\n",
    "# -------------------------------\n",
    "# Helper functions\n",
    "# -------------------------------\n",
    "\n",
    "# Clean tags (replace '|' with space, limit to 512 characters)\n",
    "def clean_tags(tags):\n",
    "    if pd.isna(tags):\n",
    "        return ''\n",
    "    return str(tags).replace('|', ' ')[:512]\n",
    "\n",
    "# Get average embedding for tags\n",
    "def get_avg_embedding(tags, model=glove_model, dim=50):\n",
    "    words = tags.split()\n",
    "    embeddings = [model[word] for word in words if word in model]\n",
    "    return np.mean(embeddings, axis=0) if embeddings else np.zeros(dim)\n",
    "\n",
    "# -------------------------------\n",
    "# Main prediction function\n",
    "# -------------------------------\n",
    "\n",
    "def predict_from_input(input_data):\n",
    "    \"\"\"\n",
    "    input_data: dict with keys - 'tags', 'duration', 'country', 'category'\n",
    "    Example:\n",
    "    {\n",
    "        'tags': \"funny|cat|cute\",\n",
    "        'duration': 300,\n",
    "        'country': \"US\",\n",
    "        'category': \"Music\"\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    # Prepare input DataFrame\n",
    "    df_input = pd.DataFrame([input_data])\n",
    "\n",
    "    if df_input['category'].iloc[0] not in ['People and Lifestyle', 'Music', 'Films', 'Travel and Vlogs','Science and Technology', 'Gaming and Sports', 'Current Affairs']:\n",
    "        \n",
    "        print(\"Enter valid category\")\n",
    "        \n",
    "        return {}\n",
    "\n",
    "    # Clean and process inputs\n",
    "    df_input['clean_tags'] = df_input['tags'].apply(clean_tags)\n",
    "    df_input['log_duration'] = np.log1p(df_input['duration'].clip(lower=0))\n",
    "    df_input['country_encoded'] = le_country.transform(df_input['country'])\n",
    "    df_input['category_encoded'] = le_category.transform(df_input['category'])\n",
    "\n",
    "    # Get tag embeddings\n",
    "    tag_embeds = df_input['clean_tags'].apply(get_avg_embedding)\n",
    "    tag_embeds = np.vstack(tag_embeds.values)\n",
    "\n",
    "    # Final feature matrix\n",
    "    X_processed = np.hstack([\n",
    "        df_input[['log_duration', 'country_encoded', 'category_encoded']].values,\n",
    "        tag_embeds\n",
    "    ])\n",
    "\n",
    "    # Predict for each target\n",
    "    predictions = {}\n",
    "    for target in target_cols:\n",
    "        pred_log = models[target].predict(X_processed)[0]\n",
    "        pred = np.expm1(pred_log)  # Reverse log1p\n",
    "        predictions[target] = pred\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "030f3be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions (original scale):\n",
      "#views: 299674.41\n",
      "#comments: 930.78\n",
      "#likes: 6823.78\n",
      "#dislikes: 302.93\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Example usage\n",
    "# -------------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sample_input = {\n",
    "        'tags': \",\",\n",
    "        'duration': 300,\n",
    "        'country': \"US\",\n",
    "        'category': \"Music\"\n",
    "    }\n",
    "\n",
    "    preds = predict_from_input(sample_input)\n",
    "    print(\"Predictions (original scale):\")\n",
    "    for target, pred in preds.items():\n",
    "        print(f\"{target}: {pred:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d954b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading lightgbm-4.6.0-py3-none-win_amd64.whl.metadata (17 kB)\n",
      "Collecting gensim\n",
      "  Downloading gensim-4.3.3-cp310-cp310-win_amd64.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\abhishek pandey\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from lightgbm) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\abhishek pandey\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from lightgbm) (1.11.1)\n",
      "Collecting smart-open>=1.8.1 (from gensim)\n",
      "  Downloading smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: wrapt in c:\\users\\abhishek pandey\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.15.0)\n",
      "Downloading lightgbm-4.6.0-py3-none-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 1.5/1.5 MB 6.9 MB/s eta 0:00:00\n",
      "Downloading gensim-4.3.3-cp310-cp310-win_amd64.whl (24.0 MB)\n",
      "   ---------------------------------------- 24.0/24.0 MB 4.0 MB/s eta 0:00:00\n",
      "Downloading smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
      "Installing collected packages: smart-open, lightgbm, gensim\n",
      "Successfully installed gensim-4.3.3 lightgbm-4.6.0 smart-open-7.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\abhishek pandey\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\abhishek pandey\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\abhishek pandey\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm gensim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3c148b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
